### 10강 k-인접기법과 판별분석



(1) k-인접기법



분류 : 학습표본 기반으로 분류하기, 지도학습으로서 타겟범주를 알고 있는 데이터로 분류규칙을 생성하고 새로운 데이터를 특정범주로 분류하는 기법



kNN(k-인접방법) : k개의 가장 가까운 이웃들을 사용해 분류하는 방법(해당 k개 내의 이웃들의 개수에 따라 분류됨)



```
따라서 k의 개수에 따라 정확도가 달라진다

k가 너무 크면 데이터 구조를 파악하기 어렵고, 너무 작으면 과적합의 위험성이 있다
=> 교차검증으로 정확도가 높은 k를 선정한다
```



```
k-인접기법의 장점 : 단순하며 효율적, 데이터 분산을 추정할 필요 없다
k-인접기법의 단점 : 모델을 생성하지 않음(중간에 설명할 부분이 부족함), 느린 분류 단계, k가 클 경우 많은 메모리 필요, 결측치는 추가 작업 필요
```



* 실습

```R
install.packages("class") # no weighted value knn(KNN 수행 패키지)
install.packages("gmodels") # crosstable(분류분석 후 검증에 사용되는 cross table)
install.packages("scales") # for graph(최적 k 등 그래프를 위한 패키지)
library(class)
library(gmodels)
library(scales)

iris<-read.csv("iris.csv")

set.seed(1000)
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE) 

iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]

trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]

train<-iris[tr.idx,]
test<-iris[-tr.idx,]

# train=학습데이터, test=검증데이터, cl=타겟변수, k=인접개수
md1<-knn(train=iris.train, test=iris.test, cl=trainLabels, k=5)
md1

# x=실제값, y=예측값, 정확도와 오분류율을 구할 수 있다
CrossTable(x=testLabels, y=md1, prop.chisq=FALSE)  # 교차표
```



```
Total Observations in Table:  50 

 
             | md1 
  testLabels |     setosa | versicolor |  virginica |  Row Total | 
-------------|------------|------------|------------|------------|
      setosa |         16 |          0 |          0 |         16 | 
             |      1.000 |      0.000 |      0.000 |      0.320 | 
             |      1.000 |      0.000 |      0.000 |            | 
             |      0.320 |      0.000 |      0.000 |            | 
-------------|------------|------------|------------|------------|
  versicolor |          0 |         13 |          2 |         15 | 
             |      0.000 |      0.867 |      0.133 |      0.300 | 
             |      0.000 |      1.000 |      0.095 |            | 
             |      0.000 |      0.260 |      0.040 |            | 
-------------|------------|------------|------------|------------|
   virginica |          0 |          0 |         19 |         19 | 
             |      0.000 |      0.000 |      1.000 |      0.380 | 
             |      0.000 |      0.000 |      0.905 |            | 
             |      0.000 |      0.000 |      0.380 |            | 
-------------|------------|------------|------------|------------|
Column Total |         16 |         13 |         21 |         50 | 
             |      0.320 |      0.260 |      0.420 |            | 
-------------|------------|------------|------------|------------|

정확도 : 96%, 오분류율 : 4%
```



* 최적 k 탐색

일반적으로는 1~20까지 탐색하는 경우가 많다



```R
nnum<-nrow(iris.train)/2   # 1부터 50까지 시행함
for(kk in c(1:nnum))
{
  set.seed(1234)
  knn_k<-knn(train=iris.train,test=iris.test,cl=trainLabels,k=kk)
  accuracy_k<-c(accuracy_k,sum(knn_k==testLabels)/length(testLabels))
}

test_k<-data.frame(k=c(1:nnum), accuracy=accuracy_k[c(1:nnum)])
min(test_k[test_k$accuracy %in% max(accuracy_k),"k"])   # 가장 정확도가 높을 때의 k 구하기

md1<-knn(train=iris.train,test=iris.test,cl=trainLabels,k=7)
# 최종 knn모형으로 한 결과 정확도가 100%가 나옴
```



![실습](https://user-images.githubusercontent.com/43332543/58534340-fb1ea080-8225-11e9-99db-b76a62673549.png)

원 data에서 setosa는 구분이 잘 되지만, versicolor와 virginica는 구분이 어렵다





* Weighted kNN(거리에 따라 가중치를 부여하는 kNN 알고리즘)

```
md2<-kknn(Species~., train=train, test=iris.test, k=5, distance=1, kernel="triangular")   # k가 5, 거리가 1(2가지 인자를 조정 가능함)

md2_fit<-fitted(md2)   # 결과 보기
CrossTable(x=testLabels, y=md2_fit, prop.chisq=FALSE, prop.c=FALSE)  # 정확도 98%

```





(2) 판별분석



판별분석 : 객체를 몇 개의 범주로 분류함, 범주들을 가장 잘 구분하는 변수와 범주 간 차이를 가장 잘 표현하는 함수를 도출한다

```
선형판별분석(LDA) : 정규분포의 분산-공분산 행렬이 범주에 관계없이 동일한 경우
이차판별분석(QDA) : 정규분포의 분산-공분산 행렬이 범주별로 다른 경우
```



현실에서는 선형으로 범주들을 구분하는 경우가 드물다



* 실습

```R
iris.lda <- lda(Species ~ ., data=train, prior=c(1/3,1/3,1/3))
# lda(종속변수 ~ 독립변수, data=학습 데이터 이름, prior=사전 확률)
# 사전확률 : 원인 A가 발생할 확률인 P(A)와 같이 결과가 나타나기 전에 결정되어 있는 확률
```



```R
Call:
lda(Species ~ ., data = train, prior = c(1/3, 1/3, 1/3))

Prior probabilities of groups:
    setosa versicolor  virginica 
 0.3333333  0.3333333  0.3333333 

Group means:   # 각 그룹별 변수들의 평균값
           Sepal.Length Sepal.Width Petal.Length Petal.Width
setosa         5.047059    3.450000     1.482353   0.2617647
versicolor     5.900000    2.748571     4.240000   1.3085714
virginica      6.500000    2.900000     5.412903   2.0096774
# Petal.Length가 데이터들을 구분하는데 가장 큰 역할을 할 것

Coefficients of linear discriminants:
                    LD1        LD2
Sepal.Length  0.7615905 -0.6507141
Sepal.Width   1.7009474 -1.2789377
Petal.Length -1.6634118  1.8487453
Petal.Width  -3.5934298 -4.2048695
# 첫 번째 범주 판별 함수 : LD1 = 0.76 Sepal.Length + 1.7 Sepal.Width - 1.66 Petal.Length - 3.59 Petal.Width
# 두 번째 범주 판별 함수 : LD1 = -0.65 Sepal.Length -1.27 Sepal.Width + 1.84 Petal.Length - 4.2 Petal.Width

Proportion of trace:
   LD1    LD2 
0.9881 0.0119  # LD1은 between-group variance의 98.8%, LD2는 1.1%를 설명함
```



```R
testpred <- predict(iris.lda, test)   # 검증 데이터 적용(각 범주별 사후 확률을 구한 다음, 가장 큰 확률에 속한 범주로 할당함)

CrossTable(x=testLabels,y=testpred$class, prop.chisq=FALSE)  # 정확도 96%
```



* 이차판별분석

| 선형판별분석                                 | 이차판별분석                          |
| -------------------------------------------- | ------------------------------------- |
| 분산-공분산 행렬이 범주 관계없이 동일한 경우 | 분산-공분산 행렬이 범주별로 다른 경우 |
| (+) 적은 파라미터를 사용함, 낮은 분산        | (-) 많은 파라미터를 사용, 높은 분산   |
| (-) 낮은 유연성                              | (+) 높은 유연성                       |



이차판별분석을 사용하기 위해서는 모집단 등분산 검정을 실행해야 한다

```R
install.packages("biotools")
library(biotools)
boxM(iris[1:4], iris$Species)
```



```R
Box's M-test for Homogeneity of Covariance Matrices

data:  iris[1:4]
Chi-Sq (approx.) = 140.94, df = 20, p-value < 2.2e-16

# 카이제곱 검정통계량, 자유도, 유의확률
# 귀무가설(모집단의 분산-공분산 행렬이 동일)이 기각되므로 QDA 시행 가능
```



```R
iris.qda <- qda(Species ~ ., data=train, prior=c(1/3,1/3,1/3))
# qda(종속변수 ~ 독립변수, data=학습 데이터 이름, prior=사전 확률)

Group means:  # 독립변수별 그룹별 평균
           Sepal.Length Sepal.Width Petal.Length Petal.Width
setosa         5.047059    3.450000     1.482353   0.2617647
versicolor     5.900000    2.748571     4.240000   1.3085714
virginica      6.500000    2.900000     5.412903   2.0096774
```



```R
testpredq <- predict(iris.qda, test)  # 검증 데이터를 모형에 넣음(추정범주와 사후 확률이 나옴)

CrossTable(x=testLabels,y=testpredq$class, prop.chisq=FALSE)   # 정확도 산정(검증데이터) -> 96%
```



```R
install.packages("klaR")
library(klaR)
# 독립변수별로 2개씩 짝을 지어 어떤 조합에서 가장 데이터 분류가 잘 되는가?
partimat(as.factor(iris$Species) ~ ., data=iris, method="lda")
partimat(as.factor(iris$Species) ~ ., data=iris, method="qda")
```



![LDA](https://user-images.githubusercontent.com/43332543/58537593-1e4d4e00-822e-11e9-82b4-9cdbaaa3c79c.png)





![QDA](https://user-images.githubusercontent.com/43332543/58537595-1e4d4e00-822e-11e9-8c57-3e6da0db7b5a.png)

QDA의 Petal.Width와 Petal.Length의 오분류율이 0.02이므로 두 변수가 가장 중요한 변수이다







